<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Design Overview</title>
    <link id='theme-link' rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>Evaluation Methods</h1>
		<button id='back' onclick='location.href="../index.html"'>Back</button>
    </header>
    <main>
		<section>
			<h2>Step 1: Define Evaluation Criteria</h2>
			<p>Establishing clear evaluation criteria is crucial for assessing the effectiveness of a design. This can include:</p>
			<ul>
				<li><strong>Formal Design Principles:</strong> Utilize established UX laws and standards to guide evaluation.</li>
				<li><strong>User Requirements:</strong> Define criteria based on target users' needs, such as maximum time to complete a task.</li>
				<li><strong>In-House Criteria:</strong> Develop criteria aligned with the specific goals of your design and company standards.</li>
			</ul>
			<p><strong>Example:</strong> If your design aims to improve task completion time, set a specific benchmark (e.g., tasks should be completed within 2 minutes).</p>
		</section>

		<section>
			<h2>Expert Evaluations</h2>
			<p>Expert evaluations involve usability experts assessing the design based on established criteria. Common approaches include:</p>
			<ul>
				<li><strong>Heuristic Evaluation:</strong> Experts use heuristics (rules of thumb) to identify usability issues.</li>
				<li><strong>Cognitive Walkthrough:</strong> An expert steps through tasks to evaluate user understanding and progress.</li>
			</ul>
			<p><strong>Example:</strong> An expert might ask, "Will users know what to do at each step?" to ensure clarity in the design.</p>
		</section>

		<section>
			<h2>Considerations for Expert Evaluations</h2>
			<p>While expert evaluations can provide valuable insights, there are important considerations:</p>
			<ul>
				<li>Experts may not fully understand the target users' context.</li>
				<li>Multiple evaluators can uncover different issues, as one evaluator might only identify about 30% of obvious problems.</li>
			</ul>
			<p><strong>Example:</strong> Engaging several experts can lead to a more comprehensive evaluation, capturing a wider range of usability issues.</p>
		</section>

		<section>
			<h2>Participant-Based Evaluations</h2>
			<p>Participant-based evaluations involve real users testing the design. Key aspects include:</p>
			<ul>
				<li>Participants should represent the target user group.</li>
				<li>Tasks should relate to specific scenarios that users would encounter in real life.</li>
			</ul>
			<p><strong>Example:</strong> If designing a banking app, participants could be asked to complete tasks like transferring money or checking their balance in a simulated environment.</p>
		</section>

		<section>
			<h2>Data Collection Methods</h2>
			<p>Data collected during evaluations can be qualitative or quantitative:</p>
			<ul>
				<li><strong>Qualitative Data:</strong> Observations of user behavior and thoughts during tasks provide insights into user experience.</li>
				<li><strong>Quantitative Data:</strong> Metrics such as time taken to complete tasks and error rates offer statistical insights into usability.</li>
			</ul>
			<p><strong>Example:</strong> A study might reveal that users take an average of 5 minutes to complete a task, indicating a need for design improvements.</p>
		</section>

		<section>
			<h2>Thinking Aloud Protocol</h2>
			<p>This method involves participants verbalizing their thoughts while using the app. It helps identify difficulties and thought processes:</p>
			<p><strong>Example:</strong> A participant might say, "Iâ€™m not sure where to find the settings," highlighting areas for improvement in navigation.</p>
		</section>

		<section>
			<h2>Controlled Experiments</h2>
			<p>Controlled experiments isolate cause and effect by manipulating variables:</p>
			<ul>
				<li><strong>Independent Variable:</strong> The factor being changed (e.g., button color).</li>
				<li><strong>Dependent Variable:</strong> The outcome being measured (e.g., click-through rate).</li>
			</ul>
			<p><strong>Example:</strong> Testing whether a red button leads to more clicks than a blue button can provide insights into user preferences.</p>
		</section>
		
        <footer>
            <p>&copy; 2024 Design Overview<br>is-104</p>
			
        </footer>
    </main>
	<script src="../bambi.js"></script>
</body>
</html>
